import rasterio
import numpy as np
import pandas as pd

# Data and Viz Libraries
import requests
import matplotlib.pyplot as plt
import time
from google.oauth2 import service_account

# Libraries for custom tile slicing functions
import os
import shutil
import csv
import json
import random
from tqdm import tqdm
from rasterio.features import geometry_mask
from rasterio.windows import Window
from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_geom


src = "F:/data science/usda imagery/"
datadir = "F:/github/freedom-camping/data/"


# adapted from https://fractaldle.medium.com/satellite-images-deep-learning-spacenet-building-segmentation-a5d145a81c33
def get_tile_name_path(dst_dir:str, index:int):
    '''
    generating index specific tile name
    '''
    dst_tile_name = "{}_.tif".format(str(index).zfill(5))
    dst_tile_path = os.path.join(dst_dir, dst_tile_name)
    return dst_tile_name, dst_tile_path

def get_tile_transform(parent_transform, pixel_x:int,pixel_y:int):
    '''
    creating tile transform matrix from parent tif image
    '''
    crs_x = parent_transform.c + pixel_x * parent_transform.a
    crs_y = parent_transform.f + pixel_y * parent_transform.e
    tile_transform = rasterio.Affine(parent_transform.a, parent_transform.b, crs_x,
                                     parent_transform.d, parent_transform.e, crs_y)
    return tile_transform
    
def get_tile_profile(parent_tif:rasterio.io.DatasetReader, pixel_x:int, pixel_y:int):
    '''
    preparing tile profile
    '''
    tile_crs = parent_tif.crs
    tile_nodata = parent_tif.nodata if parent_tif.nodata is not None else 0
    tile_transform = get_tile_transform(parent_tif.transform, pixel_x, pixel_y)
    profile = dict(
                driver="GTiff",
                crs=tile_crs,
                nodata=tile_nodata,
                transform=tile_transform
            )
    return profile

def generate_tiles(tif:rasterio.io.DatasetReader, size:int, dst_dir:str):
    i = 0
    for x in tqdm(range(0, tif.width, size)):
        for y in range(0, tif.height, size):
            # creating the tile specific profile
            profile = get_tile_profile(tif, x, y)
            # extracting the pixel data (couldnt understand as i dont think thats the correct way to pass the argument)
            tile_data = tif.read(window=((y, y + size), (x, x + size)),
                                 boundless=True, fill_value=profile['nodata'])[:3]
            i+=1
            dst_name, dst_tile_path = get_tile_name_path(dst_dir, i)
            c, h, w = tile_data.shape
            profile.update(
                height=h,
                width=w,
                count=c,
                dtype=tile_data.dtype,
            )
            with rasterio.open(dst_tile_path, "w", **profile) as dst:
                dst.write(tile_data)



mask_src = rasterio.open(f"{src}masked.tif")
img = rasterio.open(f"{src}chafee_clipped_compressed.tif")

dst_mask_dir = f"{datadir}masks"
dst_image_dir = f"{datadir}tiles"


#generate_tiles(mask_src, 1024, dst_mask_dir) # generating tiles for mask


#generate_tiles(img, 1024, dst_image_dir)


img_tmp = rasterio.open(f"{datadir}tiles/07452_.tif")
mask_tmp = rasterio.open(f"{datadir}masks/07452_.tif")

print(img_tmp.bounds)
print(img_tmp.shape)
print(img_tmp.crs)
print(img_tmp.profile)

print(mask_tmp.bounds)
print(mask_tmp.shape)
print(mask_tmp.crs)
print(mask_tmp.profile)

# Bounds should be identical, theres a slight difference here as my original mask had 1 fewer pixel in width due to an error but it should work still


r,g,b = img_tmp.read()
m = mask_tmp.read()


plt.figure(figsize=(15, 15), dpi = 300)
plt.imshow(img_tmp.read([1,2,3]).transpose(1, 2, 0))
plt.imshow(mask_tmp.read(1), alpha=0.2, vmin=0.5)
plt.title('One of 12,000, 1k resolution tiles from original composite with training labels')
plt.savefig('../output/tilemaskexample.png')


tile_path = f"{datadir}tiles"
mask_path = f"{datadir}masks"

tile_paths = os.listdir(tile_path);
mask_paths = os.listdir(mask_path);

valid_tiles=[]
train_tiles=[]

for each in tile_paths:

    img_tmp = rasterio.open(f"{tile_path}/{each}")
    mask_tmp = rasterio.open(f"{mask_path}/{each}")
    rgb = img_tmp.read()
    m = mask_tmp.read()

    if (rgb.sum()) > 0:
        valid_tiles.append(each)
        if m.sum() > 0:
            train_tiles.append(each)


print(f"number of valid tiles = {len(valid_tiles)}")
print(f"number of train tiles = {len(train_tiles)}")


test_tiles =  [e for e in valid_tiles if e not in train_tiles] 

print(f"number of test tiles = {len(test_tiles)}")


filename = 'train_tile_list'
path = f"{datadir}{filename}.csv"
with open(path, 'a'):
    os.utime(path, None)



def list_to_csv(mylist, filename):
    path = f"{datadir}{filename}.txt"
    out = csv.writer(open(path,"w"), delimiter=',',quoting=csv.QUOTE_ALL)
    out.writerow(mylist)
    return

list_to_csv(train_tiles, 'train_tile_list')
list_to_csv(test_tiles, 'test_tile_list')





import skimage.io


m = skimage.io.imread(fname=f"{datadir}train_masks/03955_.jpeg")


# compute object features and extract object areas
object_features = skimage.measure.regionprops(m)
object_areas = [objf["area"] for objf in object_features]
object_areas


object_features = skimage.measure.regionprops(m)


coords = object_features[0]['centroid'] # this is y,x so needs to be flipped for output


coords


y_top = object_features[0]['coords'][0][0]


y_bot = object_features[0]['coords'][-1][0]


height = abs(y_bot - y_top)
print(height)


x_left = object_features[0]['coords'][0][1]
x_right = object_features[0]['coords'][-1][1]

width = abs(x_right - x_left)
print(width)

norm_h = height/1024
norm_w = width/1024

norm_xcenter = coords[1] / 1024
norm_ycenter = coords[0] / 1024


yolo_annot = [['0', norm_xcenter, norm_ycenter, norm_w, norm_h]]


yolo_annot


import numpy as np
np.savetxt(f'{datadir}train_labels/04308_.txt', 
           yolo_annot,
          delimiter = ' ',
           fmt ='% s'
          )


m = skimage.io.imread(fname=f"{datadir}train_masks/04308_.jpeg")


object_features = skimage.measure.regionprops(m)
box_ycoords = np.array([int(objf["centroid"][0]) for objf in object_features])
box_xcoords = np.array([int(objf["centroid"][1]) for objf in object_features])
box_y_upbounds = np.array([objf["coords"][0][0] for objf in object_features])
box_y_lowbounds = np.array([objf["coords"][-1][0] for objf in object_features])
box_x_leftbounds = np.array([objf["coords"][0][1] for objf in object_features])
box_x_rightbounds = np.array([objf["coords"][-1][1] for objf in object_features])

    
heights = (box_y_lowbounds - box_y_upbounds) / 1024
norm_y = (((box_y_lowbounds + box_y_upbounds) / 2) / 1024)
classes = []
classes = ['0' for box in object_features]
widths = (box_x_rightbounds - box_x_leftbounds) / 1024
norm_x = ((box_x_rightbounds + box_x_leftbounds) / 2) / 1024


yolo_annot = np.array([])


box_ycoords


max(box_ycoords)


box_y_lowbounds


box_y_upbounds


heights


(box_y_lowbounds - box_y_upbounds) / 1024


box_xcoords


box_x_rightbounds


box_x_leftbounds


(box_x_rightbounds - box_x_leftbounds) / 1240


norm_x


norm_y


classes


import numpy as np
import os

train_masks = os.listdir(f"{datadir}train_masks")

for mask in train_masks:

    m = skimage.io.imread(fname = f"{datadir}train_masks/{mask}")

    object_features = skimage.measure.regionprops(m)
    box_ycoords = np.array([objf["centroid"][0] for objf in object_features])
    box_xcoords = np.array([objf["centroid"][1] for objf in object_features])
    box_y_upbounds = np.array([objf["coords"][0][0] for objf in object_features])
    box_y_lowbounds = np.array([objf["coords"][-1][0] for objf in object_features])
    box_x_leftbounds = np.array([objf["coords"][0][1] for objf in object_features])
    box_x_rightbounds = np.array([objf["coords"][-1][1] for objf in object_features])

    
    heights =  (box_y_lowbounds -  box_y_upbounds) / 1240
    norm_y = ((box_ycoords) / 1240)
    
    widths = (box_x_rightbounds - box_x_leftbounds) / 1240
    norm_x = ((box_xcoords) / 1240)
    
    classes = []
    classes = ['0' for box in object_features]


    #yolo_annot = np.array([])
    
    for i, class_id in enumerate(classes):
        
        mult_boxes = False

        if i > 0:
            print(f'{len(classes)} bounding boxes for {mask}')
            box_annot = class_id, str(norm_x[i]), str(norm_y[i]), str(widths[i]), str(heights[i])
            box_annot = ' '.join(box_annot)
            yolo_annot = [yolo_annot, box_annot]
            mult_boxes = True
            
        else:
            yolo_annot = class_id[i], str(norm_x[i]), str(norm_y[i]), str(widths[i]), str(heights[i])
            yolo_annot = ' '.join(yolo_annot)
            
    

    with open(f'{datadir}train_labels/{mask[0:6]}.txt', 'w') as f:
        
        if mult_boxes:
        
            for line in yolo_annot:
                f.write(line)
                f.write('\n')
                
        else: f.write(yolo_annot)






for infile in train_tiles:
    
    src = f"{datadir}tiles/"
    train_dir = f"{datadir}train/"
    inpath = f"{src}{infile}"
    outfile = train_dir + infile[:-3] + "jpeg"
    im = Image.open(inpath)
    out = im.convert("RGB")
    out.save(outfile, "JPEG", quality=100)

   
    #placeholder for copying annotations as well


for infile in test_tiles:
    
    src = f"{datadir}tiles/"
    test_dir = f"{datadir}test/"
    inpath = f"{src}{infile}"
    outfile = test_dir + infile[:-3] + "jpeg"
    im = Image.open(inpath)
    out = im.convert("RGB")
    out.save(outfile, "JPEG", quality=100)


train_masks = os.listdir(f"{datadir}train")


train_masks;

infile = train_masks[0]

infile = infile[:6] + ".tif"

infile


from PIL import Image

for infile in train_masks:
    
    infile = infile[:6] + ".tif"
    
    src = f"{datadir}masks/"
    train_dir = f"{datadir}train_masks/"
    inpath = f"{src}{infile}"
    outfile = train_dir + infile[:-3] + "jpeg"
    im = Image.open(inpath)
    out = im.convert("RGB")
    out.save(outfile, "JPEG", quality=100)

   
    #placeholder for copying annotations as well



